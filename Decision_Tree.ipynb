{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of classification?"
      ],
      "metadata": {
        "id": "H1dzyUkQhQIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Decision Tree is a supervised machine learning algorithm used for classification and regression.\n",
        "In classification, it works by recursively splitting the dataset based on feature values to create branches that lead to a final class label at the leaf nodes.\n",
        "\n",
        "Each internal node represents a decision rule on a feature, each branch represents the outcome of the rule, and each leaf node represents a class prediction. The goal is to create splits that maximize class purity."
      ],
      "metadata": {
        "id": "WJAC-u8RhZRY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?"
      ],
      "metadata": {
        "id": "mPToykiQherF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Gini Impurity measures the probability of incorrectly classifying a randomly chosen sample.   \n",
        "$$\n",
        "Gini = 1 - \\sum p_i^2\n",
        "$$\n",
        "- Entropy measures the level of uncertainty or randomness in the data.\n",
        "$$\n",
        "ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦ = - \\sum p_i log_2 p_i\n",
        "$$\n",
        "\n",
        "Impact on Splits:\n",
        "The decision tree selects splits that minimize impurity. Lower Gini or Entropy means purer nodes. Both measures usually produce similar trees, but Gini is faster to compute."
      ],
      "metadata": {
        "id": "hu3QGhKUhj5m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n"
      ],
      "metadata": {
        "id": "ZyC8AkwslSOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Pre-Pruning |\tPost-Pruning|\n",
        "|------------|--------------|\n",
        "|Stops tree growth early | Grows full tree then trims|\n",
        "|Uses constraints like max_depth |\tRemoves weak branches |\n",
        "|Faster training |\tBetter accuracy |\n",
        "\n",
        "Advantages:\n",
        "- Pre-Pruning: Prevents overfitting early.\n",
        "- Post-Pruning: Produces a more accurate and generalized model.\n"
      ],
      "metadata": {
        "id": "iG9ctzUxlZt5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?"
      ],
      "metadata": {
        "id": "5MKa2r8qm9nb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Information Gain measures the reduction in entropy after a dataset is split on a feature.\n",
        "$$\n",
        "ğ¼ğº = ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œğ‘ğ‘¦(ğ‘ğ‘ğ‘Ÿğ‘’ğ‘›ğ‘¡) âˆ’ \\sum(ğ‘›_ğ‘–/ğ‘› Ã—ğ¸ğ‘›ğ‘¡ğ‘Ÿğ‘œpy(ğ‘â„ğ‘–ğ‘™ğ‘‘_ğ‘–))\n",
        "$$\n",
        "It is important because it helps select the feature that best separates the data into distinct classes."
      ],
      "metadata": {
        "id": "D4BBRH7Xnehg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and what are their main advantages and limitations?"
      ],
      "metadata": {
        "id": "gsFsqOkNorcM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applications:\n",
        "- Medical diagnosis\n",
        "- Credit risk assessment\n",
        "- Customer churn prediction\n",
        "- Fraud detection\n",
        "\n",
        "Advantages:\n",
        "- Easy to interpret\n",
        "- Handles both numerical and categorical data\n",
        "- No feature scaling required\n",
        "\n",
        "Limitations:\n",
        "\n",
        "- Prone to overfitting\n",
        "- Sensitive to small data changes\n",
        "- Less accurate than ensemble methods"
      ],
      "metadata": {
        "id": "mkJxYuB0oydU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "- Load the Iris Dataset\n",
        "- Train a Decision Tree Classifier using the Gini criterion\n",
        "- Print the modelâ€™s accuracy and feature importances"
      ],
      "metadata": {
        "id": "KRVwappTpJWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load data\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = DecisionTreeClassifier(criterion=\"gini\")\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"Feature Importances:\", model.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcxPWDo3qHou",
        "outputId": "ab6ffa22-5863-4cc9-ccde-94025719ce18"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n",
            "Feature Importances: [0.01667014 0.         0.40593501 0.57739485]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "- Load the Iris Dataset\n",
        "- Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree."
      ],
      "metadata": {
        "id": "04FZYIpeqYa7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Limited depth\n",
        "model_limited = DecisionTreeClassifier(max_depth=3)\n",
        "model_limited.fit(X_train, y_train)\n",
        "acc_limited = accuracy_score(y_test, model_limited.predict(X_test))\n",
        "\n",
        "# Full tree\n",
        "model_full = DecisionTreeClassifier()\n",
        "model_full.fit(X_train, y_train)\n",
        "acc_full = accuracy_score(y_test, model_full.predict(X_test))\n",
        "\n",
        "print(\"Accuracy (max_depth=3):\", acc_limited)\n",
        "print(\"Accuracy (Full Tree):\", acc_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXYEPYdTqeFF",
        "outputId": "356ccf3e-502c-4ac9-f9ff-5dd7fe0f9e1c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (max_depth=3): 1.0\n",
            "Accuracy (Full Tree): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "- Load the Boston Housing Dataset\n",
        "- Train a Decision Tree Regressor\n",
        "- Print the Mean Squared Error (MSE) and feature importances"
      ],
      "metadata": {
        "id": "3npdQz_iqhTE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "reg = DecisionTreeRegressor(random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"Feature Importances:\", reg.feature_importances_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkXM3j0CrPx7",
        "outputId": "4ac703e9-8795-4441-be4f-f28662927f66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.495235205629094\n",
            "Feature Importances: [0.52850909 0.05188354 0.05297497 0.02866046 0.03051568 0.13083768\n",
            " 0.09371656 0.08290203]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "- Load the Iris Dataset\n",
        "- Tune the Decision Treeâ€™s max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "- Print the best parameters and the resulting model accuracy"
      ],
      "metadata": {
        "id": "x1Wg4sPZrcHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params = {\n",
        "    \"max_depth\": [2, 3, 4, 5],\n",
        "    \"min_samples_split\": [2, 5, 10]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(DecisionTreeClassifier(), params, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Best Accuracy:\", grid.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA0XWkaMrt8Z",
        "outputId": "a1b9e7cb-8483-486c-d163-ac61b392c39e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': 4, 'min_samples_split': 2}\n",
            "Best Accuracy: 0.9416666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine youâ€™re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "- Handle the missing values\n",
        "- Encode the categorical features\n",
        "- Train a Decision Tree model\n",
        "- Tune its hyperparameters\n",
        "- Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting."
      ],
      "metadata": {
        "id": "VbdfvP9Ir54S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Handle Missing Values:\n",
        "- Numerical: Mean or median imputation\n",
        "- Categorical: Mode or â€œUnknownâ€\n",
        "2. Encode Categorical Features:\n",
        "- Label Encoding or One-Hot Encoding\n",
        "3. Train Decision Tree:\n",
        "- Split data into train/test\n",
        "- Fit DecisionTreeClassifier\n",
        "4. Tune Hyperparameters:\n",
        "- Use GridSearchCV for max_depth, min_samples_split\n",
        "5. Evaluate Performance:\n",
        "- Accuracy, Precision, Recall, F1-Score, ROC-AUC\n",
        "\n",
        "Business Value:\n",
        "- Early disease detection\n",
        "- Reduced treatment cost\n",
        "- Better clinical decision support\n",
        "- Improved patient outcomes"
      ],
      "metadata": {
        "id": "Tftevxyhr_lC"
      }
    }
  ]
}